# 第10章 批处理系统

[TOC]

## 系统的分类

### 在线系统（在线服务）

​	响应时间通常是服务性能的主要衡量指标，而可用性同样非常重要。

### 离线系统（批处理系统）

 批处理系统接收大量的输入数据，运行一个作业来处理数据，并产生输出数据。

批处理作业的主要性能横量标准通常是吞吐量（处理一定大小的输入数据集所需的时间）。

### 流处理系统（近实时系统）

流处理介入在线和离线处理之间。

流式作业在事件发生后不久即可对事件进行处理，而批处理作业则使用固定的一组输入数据进行操作。这种差异使得流处理系统比批处理系统具有更低的延迟。

## UNIX工具

unix工具非常值得学习

## UNIX设计哲学

## MapReduce与分布式文件系统

MapReduce需要一个或多个输入，并产生一个或多个输出。

MapReduce作业通常不会修改输入，除了生成输出外没有任何副作用。输出文件以序列方式一次性写入（在写文件时，不会修改任何现有的文件）。

MapReduce作业在分布式文件系统上读写文件。在Hadoop的MapReduce实现中，该文件系统被称为HDFS。

与网络连接存储（NAS）和存储区域网络（SAN）架构的共享磁盘方法相比，HDFS基于无共享原则。共享磁盘存储由集中式存储设备实现，通常使用定制硬件和特殊网络基础设施（如光纤通道）。而无共享方法则不需要特殊硬件，只需要通过传统数据中心网络连接的计算机。

### MapReduce作业执行

MapReduce是一个变成框架，可以使用它编写代码来处理HDFS等分布式文件系统中的大型数据集。

### MapReduce的分布式执行

## 批处理工作流的输出

### 生成搜索索引

### 构建机器学习系统

## 对比Hadoop与分布式数据库

MPP数据库专注于在一个机器集群上并行执行SQL查询分析；而MapReduce和分布式文件系统的结合则更像是一个可以运行任意程序的通用操作系统。

### 存储多样性

Hadoop开放了将数据不加区分地转存到HDFS的可能性，之后再去考虑如何进一步处理数据。相比之下，在将数据导入数据库的专有存储格式之前，MPP数据库通常需要对数据和查询模型进行仔细的前期建模。

将大型组织中各个部分的数据集中在一起是非常有价值的，因为它可以在之前完全分离的数据集执行join操作。MPP数据库所秉持的谨慎设计模式减慢了集中式数据的收集速度；因此，仅仅以原始形式收集数据，之后再考虑模式设计，从而使收集数据的速度加快（这种形式有时也被称为“**数据湖**”或“企业数据中心”）。

因此，Hadoop经常被用于实现ETL过程：来自事务处理系统的数据以某种原始形式转储到分布式文件系统中，然后编写MapReduce作业进行数据清理，将其转换为关系表单，并将其导入MPP数据仓库以进行分析。

### 处理模式的多样性

MPP数据库属于一体化、紧密集成的软件系统，包括磁盘存储布局、查询计划、调度和执行。由于这些组件都可以针对数据库的特定需求进行调整和优化，因此整个系统可以在其设计的查询类型上实现非常好的性能。此外，SQL查询语言支持表达式查询，以及优雅的语义，因此，业务分析人员使用图形化工具（如Tableau）即可执行查询。

并非所有类型的处理都可以表达为SQL查询。例如，如果正在构建机器学习和推荐系统，或具有相关性排名模型的全文搜索索引，或执行图像分析，则很可能需要更具一般性的数据处理模型。这些类型的处理通常特定于专门的应用程序（例如机器学习的特征工程，机器翻译的自然语言模型，欺诈预测的风险评估功能），所以不可避免的需要编写代码，而不仅仅是查询。

MapReduce使工程师能够轻松地在大型数据集上运行自己的代码。如果你有HDFS和MapReduce，可以在它上面建立一个SQL查询执行引擎，事实上这就是Hive项目所做的事情。也可以编写许多其它形式的不适合用SQL查询表示的批处理。

随后，人们发现MapReduce对于某些类型的处理局限性太大，而且执行的太差，因此在Hadoop之上开发了各种其他的处理模型。仅有SQL和MapReduce两种处理模型还不够，我们需要更多不同的模型！而且由于Hadoop平台的开放性，实施一整套处理方法也是可行的，但对于一体化的MPP数据库来说则力所不及。

至关重要的是，这些不同的处理模型都可以在一个共享的机器集中中运行，所有机器都可以访问分布式文件系统上的相同文件。**在Hadoop方法中，不需要将数据导入到几个不同的专用系统中进行不同类型的处理**：系统已经足够灵活，可以支持同一集群中不同的工作负载。无需移动数据使得从数据中获取价值变得容易的过，而且更容易使用新的处理模型进行测试。

Hadoop生态系统包括可以随机访问的OLTP数据库，如HBase以及MPP模式的分析数据库，如Impala。HBase和Impala都不使用MapReduce，但都是用HDFS进行存储。尽管它们访问和处理数据的方法差异很大，但是可以共存并被集成到同一个系统中。

### 针对频繁故障的设计

如果一个节点在执行查询时崩溃，大多数MPP数据库会中止整个查询，并让用户重新提交查询或自动重新运行查询。由于查询通常最多运行几秒或者几分钟，所以这种处理错误的方式是可以接受的，因为重试的代价不是太大。MPP数据库还倾向于在内存中保留尽可能多的数据（例如使用哈希join）以避免磁盘读取的成本。

MapReduce被设计为容忍意外任务终止的原因：不是因为硬件特别不可靠，而是因为任意终止进程的灵活性能够更好地利用集群资源。在任务不经常被终止的环境中，MapReduce的设计决策没有多少意义。

## 批处理的其它方案（超越MapReduce）

MapReduce只是分布式系统的许多可能的变成模型之一。

MapReduce是一个有用的学习工具，它是分布式文件系统的一个相当清晰和简单的抽象。简单是指从理解它在做什么的角度来说，而不是容易使用的角度。事实上与容易使用恰恰相反；使用原始的MapReduce API来实现一个复杂的处理任务是相当困难和费力的，例如，你需要从头开始实现全部join算法。

针对直接使用的困难，在MapReduce上创建了各种高级编程模型（Pig，Hive，Cascading，Crunch）进一步封装抽象。

### 中间状态实体化

一个作业的输出只能用作另一个作业的输入，在这种情况下，分布式文件系统上的文件只是中间状态：一种将数据从一个作业传递到下一个作业的方式。在用于构建由50个或100个MapReduce作业组成的推荐系统的复杂工作流中，存在很多这样的中间状态。**将这个中间状态写入文件的过程称为实体化（或物化）。它主要是指提前计算某些操作的结果并将其写入磁盘，而不是在需要时才进行计算。**

### 数据流引擎

为了解决MapReduce的实体化等问题，开发了用于分布式批处理的心的执行引擎，其中最著名的是Spark、Tez和Flink。它们的设计方式有很多不同之处，但有一个共同点：它们把整个工作流作为一个作业来处理，而不是把它分解成独立的子作业。

可以使用数据流引擎来执行与MapReduce工作流相同的计算，并且由于数据流引擎的优化，通常执行速度会明显加快。

### 容错

将中间状态完全实体化到分布式文件系统的一个优点是持久化，这使得在MapReduce中实现容错变得相当容易：如果一个任务失败了，它可以在另一台机器重新启动，并从文件系统重新读取相同的输入。

Spark、Flink和Tez避免将中间状态写入HDFS，所以它们采取不同的方法来容忍错误：如果机器发生故障，并且该机器上的中间状态丢失，则利用其它可用的数据重新计算。

为了实现重新计算，框架必须追踪给定数据是如何计算的，使用了哪个输入分区，以及应用了哪个运算符。Spark使用弹性分布式数据集合（Resilient Distributed Dataset RDD）抽象来追踪数据的祖先，而Flink队运算符状态建立检查点，从而运行将执行过程中遇到故障的运算符恢复运行。

**通过重新计算数据以实现从故障中恢复并不总是能得到正确的答案：如果中间数据比源数据小的多，或者计算量非常大，那么将中间数据转化为文件比重新计算文件的代价要小。**
